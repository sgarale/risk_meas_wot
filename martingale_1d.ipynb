{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import nn_utils as nn_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting latex style for plots\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the payoff function\n",
    "\n",
    "K1 = 0.9\n",
    "K2 = 1.2\n",
    "def f(x):\n",
    "    return torch.maximum(x - K1, torch.tensor(0.)) - torch.maximum(x - K2, torch.tensor(0.))\n",
    "\n",
    "plt.plot(torch.arange(0.75,1.25,0.01), f(torch.arange(0.75,1.25,0.01)), label='payoff function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the reference measure\n",
    "\n",
    "sigma = 0.20\n",
    "t = .5\n",
    "mu = torch.distributions.LogNormal(- 0.5 * sigma * sigma * t, sigma * math.sqrt(t))\n",
    "\n",
    "samples = mu.sample([100000])\n",
    "plt.hist(samples.detach().numpy(), 300, label='reference measure')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost functional\n",
    "p = 3\n",
    "h = 1. / 12\n",
    "def cost(u):\n",
    "    return h * torch.pow(torch.absolute(u) / math.sqrt(h), p)\n",
    "\n",
    "### risk measure by neural network approximation\n",
    "\n",
    "# fixing the seed\n",
    "torch.manual_seed(29)\n",
    "\n",
    "# defining the risk measure object\n",
    "width = 20\n",
    "depth = 4\n",
    "sample_size = 100\n",
    "risk_measure = nn_ut.MartRiskMeasure1d(f, cost, mu, torch.nn.ReLU, width, depth)\n",
    "\n",
    "# otpimizer\n",
    "optim = torch.optim.Adam(risk_measure.parameters(), lr=0.001)\n",
    "\n",
    "# training cycle\n",
    "train_hist = []\n",
    "epochs = 20000\n",
    "for i in range(epochs):\n",
    "    optim.zero_grad()\n",
    "    y = mu.sample([sample_size,1])\n",
    "    risk = risk_measure(y)\n",
    "    risk.backward()\n",
    "    optim.step()\n",
    "    train_hist.append(- float(risk.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training phase\n",
    "\n",
    "roll_window = 100\n",
    "train_roll = pd.Series(train_hist).rolling(roll_window).mean().dropna()\n",
    "\n",
    "final_samples = mu.sample([100000,1])\n",
    "expected_loss = torch.mean(f(final_samples))\n",
    "plt.plot(1 + np.arange(roll_window, epochs + 1), train_roll, label=f'sup')\n",
    "plt.axhline(float(expected_loss), color='green', label='expected payoff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "risk_measure.eval()\n",
    "\n",
    "mc_rm = -risk_measure(final_samples)\n",
    "mc_err = 2.57 * risk_measure.mc_err\n",
    "print(f\"risk measure mc: {mc_rm:.3e}\")\n",
    "print(f\"Mc interval: [{mc_rm - mc_err:.3e}, {mc_rm + mc_err:.3e}]\")\n",
    "print(f\"Expected value: {expected_loss:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results\n",
    "\n",
    "x_plot = torch.arange(0.75, 1.25, 0.01)\n",
    "net_plot = risk_measure.unet(x_plot.reshape(-1, 1))\n",
    "u_plot, v_plot, p_plot = risk_measure._u_v_p(x_plot.reshape(-1, 1))\n",
    "ccong = risk_measure.ccong(x_plot.reshape(-1, 1))\n",
    "plt.plot(x_plot.detach(), f(x_plot).detach(), label='payoff function', color='blue')\n",
    "plt.plot(x_plot.detach(), ccong.detach(), label=r'$C$-transform', color='green')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_plot, u_plot.detach(), color='blue', label=r'$u^*$')\n",
    "ax1.plot(x_plot, v_plot.detach(), color='green', label=r'$v^*$')\n",
    "ax1.set_xlabel(r'$x$')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_plot, p_plot.detach(), color='red', label=r'$p^*$')\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "legend = ax1.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-measures-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
